{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "test_data = pd.read_csv('..\\\\raw_data\\\\raw_data\\\\balancedtest.csv', header=None, names=['label', 'text'])\n",
    "X_test_texts = test_data['text'].values\n",
    "y_test = test_data['label'].values\n",
    "# Use the same label_encoder that was used for training data\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "y_test_categorical = to_categorical(y_test_encoded)\n",
    "# Use the same tokenizer that was used for training data\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test_texts)\n",
    "# Use the same max_length that was used for training data\n",
    "X_test_pad = pad_sequences(X_test_seq, maxlen=max_length, truncating='post')\n",
    "np.random.seed(42)  # Ensures reproducibility\n",
    "additional_features_test = np.random.rand(len(X_test_texts), 10)\n",
    "# Use the same selector that was used for training data\n",
    "additional_features_test_selected = selector.transform(additional_features_test)\n",
    "# Normalize additional features\n",
    "scaler = MinMaxScaler()\n",
    "additional_features_test_scaled = scaler.transform(additional_features_test)\n",
    "print(\"Shape of X_test_pad:\", X_test_pad.shape)\n",
    "print(\"Shape of additional_features_test_scaled:\", additional_features_test_scaled.shape)\n",
    "\n",
    "# Evaluate the trained model on the test data\n",
    "loss, accuracy = model.evaluate([X_test_pad, additional_features_test_scaled], y_test_categorical)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "\n",
    "# Corrected prediction step\n",
    "predictions = model.predict([X_test_pad, additional_features_test_scaled])\n",
    "# Since the output is in probabilities, you need to convert these to class indices\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Calculate the F1 score\n",
    "f1 = f1_score(y_test_encoded, predicted_labels, average='weighted')  # Use the label-encoded version of y_test\n",
    "print(f'F1 Score: {f1}')\n",
    "\n",
    "# Calculate and print the confusion matrix using the corrected variables\n",
    "conf_matrix = confusion_matrix(y_test_encoded, predicted_labels)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "# Use the same label_encoder that was used for encoding training and testing data\n",
    "sns.heatmap(conf_matrix, annot=True, cmap='Blues', fmt='g', xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
