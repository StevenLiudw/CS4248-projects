# CS4248-project

### GPT

There are 2 files for GPT, one for the standard fine-tuning without preprocessing and the other incorporates the features into the final layer. These notebooks were run in Kaggle. The notebooks include the hyperparameters that produced thge best results, but note that some of the cell outputs were from later runs which were not the best. Simply run the cells in sequence to reproduce the output.

### BERT

There is only 1 file for BERT. It includes the training codes of BERT both with and without summarized text. They were run in local machine, with CPU training. To train the BERT model with the code, choose from 3 of the cells for the input data first, and then run the remaining cells in sequence.
